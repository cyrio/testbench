{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diagrams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-02fed7b680fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdiagrams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDiagram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiagrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlretrieve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdiagrams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mazure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatabase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diagrams'"
     ]
    }
   ],
   "source": [
    "from diagrams import Cluster, Diagram\n",
    "from diagrams.custom import Custom\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "from diagrams.azure.database import DataFactory\n",
    "from diagrams.azure.analytics import EventHubs\n",
    "from diagrams.azure.analytics import StreamAnalyticsJobs\n",
    "from diagrams.azure.storage import DataLakeStorage\n",
    "\n",
    "from diagrams.azure.analytics import Databricks\n",
    "from diagrams.azure.ml import MachineLearningServiceWorkspaces\n",
    "\n",
    "from diagrams.onprem.analytics import PowerBI\n",
    "from diagrams.azure.analytics import SynapseAnalytics\n",
    "\n",
    "from diagrams.onprem.vcs import Github\n",
    "from diagrams.azure.compute import AKS\n",
    "\n",
    "with Diagram(\"Test Bench Azure Architecture\", show=False) as diag:\n",
    "    \n",
    "    # Custom icons\n",
    "    sensor_url = \"https://cdn-icons-png.flaticon.com/512/2540/2540201.png\"\n",
    "    sensor_icon = \"sensor.png\"\n",
    "    urlretrieve(sensor_url, sensor_icon)\n",
    "    \n",
    "    csvfile_url = \"https://cdn-icons-png.flaticon.com/512/180/180855.png\"\n",
    "    csvfile_icon = \"csvfile.png\"\n",
    "    urlretrieve(csvfile_url, csvfile_icon)\n",
    "    \n",
    "    deltalake_url = \"https://camo.githubusercontent.com/5535944a613e60c9be4d3a96e3d9bd34e5aba5cddc1aa6c6153123a958698289/68747470733a2f2f646f63732e64656c74612e696f2f6c61746573742f5f7374617469632f64656c74612d6c616b652d77686974652e706e67\"\n",
    "    deltalake_icon = \"deltalake.png\"\n",
    "    urlretrieve(deltalake_url, deltalake_icon)\n",
    "\n",
    "\n",
    "\n",
    "    # Clusters\n",
    "    with Cluster(\"Déploiement\"):\n",
    "        aks = AKS(\"AKS\")\n",
    "    \n",
    "    with Cluster(\"CI/CD et versionning\"):\n",
    "        github = Github(\"GitHub\")\n",
    "        github >> aks\n",
    "\n",
    "    with Cluster(\"Insight\"):\n",
    "        powerBI = PowerBI(\"Power BI\")\n",
    "\n",
    "    with Cluster(\"Analytique\"):\n",
    "        synapse = SynapseAnalytics(\"Synapse\")\n",
    "        \n",
    "        \n",
    "    with Cluster(\"Machine Learning\"):\n",
    "        databricks = Databricks('Azure Databricks')\n",
    "        azureML = MachineLearningServiceWorkspaces(\"Azure ML\")\n",
    "        databricks - azureML\n",
    "        github << databricks\n",
    "        github >> databricks >> powerBI\n",
    "        azureML >> aks\n",
    "    \n",
    "    with Cluster(\"Data Lakehouse\"):\n",
    "        datalake = DataLakeStorage('ADLS Gen2')\n",
    "        deltalake = Custom(\"\", deltalake_icon)\n",
    "        datalake - deltalake\n",
    "        deltalake >> databricks\n",
    "        deltalake >> synapse >> powerBI\n",
    "        \n",
    "    with Cluster(\"Ingestion\"):\n",
    "        eventhubs = EventHubs('Event Hubs')\n",
    "        streamanal = StreamAnalyticsJobs(\"Stream Analytics\")\n",
    "        datafactory = DataFactory('Data Factory')\n",
    "        eventhubs >> streamanal >> datalake\n",
    "        datafactory >> datalake\n",
    "        eventhubs >> databricks\n",
    "\n",
    "    with Cluster(\"Source des données\"):\n",
    "        Custom(\"Capteurs\", sensor_icon) >> eventhubs\n",
    "        Custom(\"Fichiers CSV\", csvfile_icon) >> datafactory\n",
    "\n",
    "diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
